# ğŸ’§ MiÃ£ga: Modelo Leve de IA para AnÃ¡lise da Qualidade da Ãgua

MiÃ£ga Ã© um modelo de inteligÃªncia artificial treinado com fine-tuning no Qwen2.5-3B, desenvolvido especificamente para interpretar dados de qualidade da Ã¡gua e gerar relatÃ³rios tÃ©cnicos em linguagem natural, com base nos parÃ¢metros fÃ­sico-quÃ­micos e nos Ã­ndices ambientais (como IQA e IET). Ã‰ voltado para aplicaÃ§Ãµes pÃºblicas e privadas, sendo compatÃ­vel com ambientes de baixo custo (CPU) e escalÃ¡vel para ambientes com GPU.

---

## ğŸ“¦ Estrutura deste RepositÃ³rio

```bash
.
â”œâ”€â”€ model/                   # Arquivos do modelo LoRA adaptado (MiÃ£ga)
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ vocab.json
â”‚   â”œâ”€â”€ merges.txt
â”‚   â”œâ”€â”€ added_tokens.json
â”‚   â””â”€â”€ chat_template.jinja
â”œâ”€â”€ app.py                   # FastAPI com endpoint para inferÃªncia
â”œâ”€â”€ requirements.txt         # DependÃªncias da aplicaÃ§Ã£o
â”œâ”€â”€ start.sh                 # Script de inicializaÃ§Ã£o para o Render
â””â”€â”€ README.md                # Este arquivo
```

---

## ğŸ§  Modelo Base

- **Modelo base:** [`Qwen/Qwen2.5-3B-Instruct`](https://huggingface.co/Qwen/Qwen2.5-3B-Instruct)
- **TÃ©cnica:** Fine-tuning com QLoRA
- **Arquitetura:** Causal LM (decoder-only)
- **Tamanho do adapter:** ~390MB
- **TokenizaÃ§Ã£o:** AutoTokenizer compatÃ­vel com Qwen
- **Formato de resposta:** Texto tÃ©cnico estruturado com trÃªs seÃ§Ãµes:
  - DiagnÃ³stico
  - Causas/Impactos
  - RecomendaÃ§Ãµes

---

## ğŸš€ Como rodar localmente

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/miaga-api.git
cd miaga-api
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Execute o servidor de inferÃªncia

```bash
python app.py
```

### 4. Use a API (via `curl`, `Postman` ou front-end)

**Endpoint:** `POST /gerar`

**Corpo da requisiÃ§Ã£o:**

```json
{
  "entrada": "Rio Chamagunga - Ponto: C1 - IQA: 55, C2 - IQA: 70"
}
```

---

## ğŸŒ Deploy no Render

Este repositÃ³rio estÃ¡ pronto para ser hospedado no [Render.com](https://render.com/). Basta seguir os passos:

1. Crie um novo serviÃ§o **Web Service** com linguagem **Python**.
2. Aponte para este repositÃ³rio do GitHub.
3. Configure a porta como `8000`.
4. No campo **Start Command**, use:

```bash
bash start.sh
```

5. Defina a branch como `main` e clique em "Create Web Service".

---

## ğŸ“Š Benchmarks Operacionais

### Ambiente de Teste

| Recurso        | GPU (Colab Pro)        | CPU (Colab Pro)        |
|----------------|------------------------|------------------------|
| MemÃ³ria RAM    | 15.2 GB                | 51.0 GB                |
| Sistema        | Ubuntu 22.04           | Ubuntu 22.04           |

### Indicadores

| MÃ©trica                        | GPU           | CPU           |
|-------------------------------|---------------|---------------|
| LatÃªncia mÃ©dia (s)            | 77.04         | 199.04        |
| Tempo mÃ­nimo (s)              | 67.63         | 177.16        |
| Tempo mÃ¡ximo (s)              | 81.94         | 218.16        |
| Desvio-padrÃ£o (s)             | 4.63          | 16.81         |
| Throughput (relatÃ³rios/min)   | 0.78          | 0.30          |
| Pico estimado de RAM (MB)     | 300           | 5800          |
| Tamanho do adapter (MB)       | 390           | 390           |

---

## ğŸ§ª Exemplo de InferÃªncia

```python
entrada = "Rio das Contas - Ponto: R01 - IQA: 80"
resposta = gerar_relatorio(entrada)
print(resposta)
```

---

## ğŸ“š ReferÃªncia TÃ©cnica

Este modelo foi treinado com um dataset composto por 5700 exemplos sintÃ©ticos e reais (dados do SEIA/INEMA), validado com testes manuais e mÃ©tricas tÃ©cnicas como `loss` e `perplexidade`.

---

## ğŸ§  AplicaÃ§Ãµes

- Monitoramento automÃ¡tico de rios e reservatÃ³rios
- Apoio a relatÃ³rios de Ã³rgÃ£os ambientais
- Ferramentas educacionais para ensino de sustentabilidade

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT e faz parte da plataforma **Tikatu**, com fins cientÃ­ficos e educacionais.

---

## ğŸ¤ ColaboraÃ§Ã£o

SugestÃµes, colaboraÃ§Ãµes e forks sÃ£o bem-vindos!  
Para dÃºvidas e suporte: **contato@tikatu.com.br**

---
